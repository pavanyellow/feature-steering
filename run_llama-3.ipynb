{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation import Llama\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "os.environ['RANK'] = '0'  # Example rank, adjust accordingly\n",
    "os.environ['WORLD_SIZE'] = '1'  # Example world size, adjust accordingly\n",
    "os.environ['MASTER_ADDR'] = 'localhost'  # Example master address\n",
    "os.environ['MASTER_PORT'] = '12355'  # Example master port\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 37.20 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llama = Llama.build(ckpt_dir= \"../llama3/Meta-Llama-3-8B-Instruct/\", tokenizer_path=\"../llama3/Meta-Llama-3-8B-Instruct/tokenizer.model\", max_seq_len= 512, max_batch_size = 4, model_parallel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "cuda = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama.model.to(cuda)\n",
    "model = llama.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = llama.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for travel tips and recommendations<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{user_prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(prompt: str):\n",
    "    return torch.tensor(tokenizer.encode(prompt_template.format(user_prompt = prompt), eos= False, bos = False), dtype= torch.long).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt_tokens = get_prompt(\"Write a poem in 1000 words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant for travel tips and recommendations<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Write a poem in 1000 words<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(prompt_tokens[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:09<00:00, 26.53it/s]\n"
     ]
    }
   ],
   "source": [
    "out_tokens = llama.generate(prompt_tokens.tolist(), max_gen_len= 256, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A world of wonder, a world of might,\n",
      "Where cultures blend and stories take flight,\n",
      "A tapestry rich, with threads of old,\n",
      "A journey awaits, for hearts of gold.\n",
      "\n",
      "In cities bustling, with sounds and sights,\n",
      "Where ancient ruins whisper secrets at night,\n",
      "In mountains towering, where eagles soar,\n",
      "And oceans vast, where dolphins play once more.\n",
      "\n",
      "In markets vibrant, with colors bright,\n",
      "Where spices waft, and aromas take flight,\n",
      "In temples serene, with incense and prayer,\n",
      "Where souls connect, and hearts are aware.\n",
      "\n",
      "In forests dark, where myths unfold,\n",
      "Where creatures roam, and legends are told,\n",
      "In deserts vast, where stars shine bright,\n",
      "Where nomads roam, and stories take flight.\n",
      "\n",
      "In every place, a story's told,\n",
      "Of people, places, and moments old,\n",
      "Of struggles, triumphs, and hearts that beat,\n",
      "Of dreams that soar, and souls that meet.\n",
      "\n",
      "A world of wonder, a world of might,\n",
      "Where cultures blend, and stories take flight,\n",
      "A journey awaits, for hearts of gold,\n",
      "To explore, to discover, to unfold.\n",
      "\n",
      "In every step, a new tale's spun,\n",
      "Of people, places, and moments won,\n",
      "Of laughter, tears, and hearts that ache,\n",
      "Of love that\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out_tokens[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_tokens[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198,    27,    91,  7413,  3659,  4424,    91,  1822,    91,  2527,\n",
       "          8932,   851,    91,    29,  9125,    27,    91,   408,  8932,   851,\n",
       "            91,  1363,  2675,   527,   264, 11190, 15592, 18328,   369,  5944,\n",
       "         10631,   323, 19075,    27,    91,    68,   354,   851,    91,   397,\n",
       "            27,    91,  2527,  8932,   851,    91,    29,   882,    27,    91,\n",
       "           408,  8932,   851,    91,  1363,  8144,   264, 33894,   304,   220,\n",
       "          1041,    15,  4339,    27,    91,    68,   354,   851,    91,  1822,\n",
       "            91,  2527,  8932,   851,    91,    29, 78191,    27,    91,   408,\n",
       "          8932,   851,    91,  1363]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
